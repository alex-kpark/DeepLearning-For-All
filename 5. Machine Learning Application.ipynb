{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 1 : Manage Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 발생할 수 있는 문제들\n",
    "\n",
    "**Overshooting** : Learning Rate이 너무 커서 그래프 밖으로 예측 값이 나가버리는 것\n",
    "\n",
    "**Local Minimum**: Learning Rate이 너무 작아서 Local Minimum 값에 머무르게 되는 것\n",
    "\n",
    "**합리적인 방법** : 처음에는 Learning Rate을 0.01로 두고, 발산하면 줄이거나 너무 느리게 움직이면 크게 키우면서 맞추어가야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 2 : Pre-Processing의 필요성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1, x2의 **값의 숫자 차이가 너무 커서**, \n",
    "\n",
    "예를 들어, w1과 w2를 구하는데 필요한 x1, x2 변수값이\n",
    "\n",
    "x1 = [1,2,3,4,5]\n",
    "x2 = [9000, -5000, -2000, 3000, 4000] 면 학습이 제대로 되지 않는 경우가 많다.\n",
    "\n",
    "이러한 경우에는, Normalization을 사용해서 숫자간의 차이를 크지 않게 만들어주는 것이 필요하다. 주로 많이 쓰는 방법은 흔히 정규화라고 쉽게 알려져 있는 **Standardization**을 쓰는 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 3 : Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting이란** : Training Data Set에 학습시킨 알고리즘이 최적화되어있어서 새로운 데이터가 들어왔을 때 제대로 결과를 내지 못하는 경우를 의미함\n",
    "\n",
    "**Overfitting을 해결하기 위한 솔루션으로는**\n",
    "\n",
    "1) Training Data Set을 많이 확보하기\n",
    "\n",
    "2) Feature의 개수 자체를 줄여보기\n",
    "\n",
    "3) Regularization(일반화) : 우리가 가지고 있는 Weight 값을 줄이는 것을 의미한다\n",
    "\n",
    "의 3가지 방법을 주로 사용할 수 있다.}\n",
    "\n",
    "여기서 **3) Regularization**은\n",
    "\n",
    "그래프에서 구분하는 선이 구부러지는 경우 우리가 흔히 Overfitting이 잘 일어난다고 할 수 있는데, 이 구부러지는 구분선 자체를 펴주는 것으로 직관적으로 생각해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 4 : 머신러닝 모델이 잘 돌아가는 지 확인하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Evaluation**\n",
    "\n",
    "한 번 Training Set을 학습시킨 다음에, 그 데이터를 다시 넣는 것은 의미가 없다 (한 번 풀었던 문제를 시험에 사용하는 것과 같음)\n",
    "\n",
    "**Testing Set**\n",
    "\n",
    "전체 데이터에서 30% 가량의 데이터는 사용하지 않고 남겨둔 다음, 70%의 데이터만을 가지고 학습시킨다. 그리고 나머지 Testing Set을 가지고 Performance를  Evaluation 하는 것이다. (일종의 본 시험이라고 생각할 수 있음)\n",
    "\n",
    "**Validation Set**\n",
    "\n",
    "Training Set 안에서도, Regularization에 필요한 람다 값등을 조정하는데 Validation Set을 이용해서 조정한다 (일종의 모의고사처럼 생각할 수 있음)\n",
    "\n",
    "\n",
    "\n",
    "![sets](img/sets.png)\n",
    "\n",
    "\n",
    "**Online Learning**\n",
    "\n",
    "DataSet이 너무 많은 경우, 이러한 것들을 메모리에 올리기 어려운 경우가 많다. 예를 들어, 데이터가 100만개가 있다고 할 때 모두 한 번에 메모리에 올려 학습시킬 수 없으므로,\n",
    "\n",
    "100만개를 10만개씩 잘라서 학습시키는 방법을 적용할 수 있다.\n",
    "\n",
    "이 때, 처음으로 학습시킨 10만개의 데이터 결과에 따른 weight 값들은 학습시킨 알고리즘 자체에 저장되어있어야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

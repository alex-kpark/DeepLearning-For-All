{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN 기초\n",
    " \n",
    "### 구성\n",
    "\n",
    "Convolutional Layer - ReLU - Convolutional Layer - ReLU - Pooling.. 을 쭉 반복하다가 마지막에 Fully Connected Neural Network를 구성해서 마지막에 Labelling을 해주는 형식으로 구성됨 \n",
    "\n",
    "### 이미지 형태\n",
    "\n",
    "예를 들어, 32(가로) x 32(가로) x 3(RGB 3가지 값)의 이미지가 있다고 가정할 수 있다. (일종의 벡터라고 생각하면 편안함)\n",
    "\n",
    "### 필터 사이즈 계산\n",
    "\n",
    "32 x 32 x 3 의 이미지가 있다고 할 때, Filter를 설정할 수 있음. 예를 들어, 5 x 5 x 3의 형태로 Filter를 만들어낼 수 있다. 필터의 역할은 특정 구역의 이미지를 뽑아내어 하나의 값(One Number)로 만들어내는 기능을 수행한다.\n",
    "\n",
    "ReLU(Wx+b)의 형태를 이용해서 하나의 값으로 만들어낸다. 즉, w1 * x1 + w2 * x2 + ... + w5 * x5 를 계산해서 나온 하나의 값을, ReLU 함수에 호출해서 넣어주는 개념으로 생각하면 된다.\n",
    "\n",
    "이 때 사용한 필터를 옆으로, 혹은 밑으로 \"stride 만큼\" 필터를 넘겨주면서 전체 이미지를 쭉 훑어가면서 각 영역들에서 상수값을 만들낸다. 전체 총 나오는 필터의 결과값의 갯수 만큼 값이 나오는데, 한 변이 N, 필터의 한 변 크기가 F일 때, 한 변에서 {(N - F) / stride} + 1 의 식 만큼 필터를 통과한 결과값이 나오게 된다.\n",
    "\n",
    "즉, 각 변에서 {(N-F)/stride + 1} 만큼 몇개가 나오는지 계산하면, 필터의 사이즈를 계산할 수 있다.\n",
    "\n",
    "### Padding\n",
    "\n",
    "**실제로 사용할 때**는, 이미지의 가장자리에는 Padding(모서리) 부분에 0값을 넣어준다. 이는,\n",
    "\n",
    "1) 이미지가 급격하게 작아지는 문제를 예방하고\n",
    "\n",
    "2) 주위에 필요없는 이미지 요소들을 없앨 수 있다\n",
    "\n",
    "Padding을 준다는 것은 이미지에 Padding의 크기만큼의 픽셀을더 붙여준다고 생각하면 된다.\n",
    "\n",
    "Padding을 1만큼 주고 필터를 생성하면, 처음에 넣은 이미지와 동일한 사이즈의 Filter를 거친 Convolution 결과 이미지가 생성된다\n",
    "\n",
    "\n",
    "### 필터를 여러개 동시에 적용시키면?\n",
    "\n",
    "32 x 32 x 3 이미지에서 (5 x 5 x 3) 짜리로 6개 다른 필터를 만들면, (28 x 28 x 6) 의 Convolutional Layer의 계층이 만들어진다.\n",
    "\n",
    "(28 x 28 x 6) 에서 앞의 28 x 28은 필터 사이즈를 의미하고, 마지막 6은 몇 번 반복했는지, 즉 몇 개의 필터가 반복되었는지를 의미한다.\n",
    "\n",
    "그 다음에 또 한번 적용시키는 Convolutional Layer의 갯수는 6개와 동일해야 한다.\n",
    "\n",
    "\n",
    "### Weight의 개수는 어떻게 정해지는가? \n",
    "\n",
    "처음에는 5 x 5 x 3 x 6개 처럼, 필터의 width, height, rgb 값, 새롭게 만든 필터의 갯수를 모두 곱해서 계산할 수 있다\n",
    "\n",
    "\n",
    "### Pooling이란?\n",
    "\n",
    "필터를 사용할 때 여러 개의 필터를 사용한다. 이 때, 필터 하나를 뽑아서 Sampling을 하고, 다른 필터들에게서도 똑같이 적용해서 필요한 부분만 뽑아내는 것을 Pooling이라고 한다. 전체의 값들 중에서 특정한 조건을 가진 것만을 뽑아내기 때문에 Sampling이라는 개념으로 볼 수 있음.\n",
    "\n",
    "* Max Pooling : 가장 큰 값을 뽑아내는 것\n",
    "\n",
    "\n",
    "### Fully Connected Layer란?\n",
    "\n",
    "마지막에 softmax function 등 실질적인 구분에 필요한 function을 쓰는 단계의 층을 의미한다.\n",
    "\n",
    "Convolution, Subsampling을 계속 반복하는 과정에서 Feature Extraction을 하다가, 마지막에 Fully Connected Layer에서 의사결정을 내린다고 볼 수 있다.\n",
    "\n",
    "\n",
    "### Convolution이란?\n",
    "\n",
    "값을 움직여나가면서 계속 더해나간다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN 구성요소의 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필터는 어떤 기능을 하는가?\n",
    "\n",
    "필터는 입력받은 데이터에서 그 \"특성을 가지고 있으면 큰 결과값을 내고\", 특성을 가지고 있지 않으면 결과값이 0에 가까운 값이 나오게 되면서 데이터가 그 특성을 가지고 있는지 없는지 여부를 알게 해준다.\n",
    "\n",
    "즉, 필터는 특정 Feature가 있으면 그것에 대해 더 큰 값을 주는 역할을 한다.\n",
    "\n",
    "\n",
    "#### Activation Function(ReLU)는 어떤 기능을 하는가?\n",
    "\n",
    "필터를 통해서 Feature Map이 만들어진 다음에 참/거짓으로 구분하는 것이 아니라, 참에 가까워지면 더 큰 값을 내는 식으로 표현해주기 위함이다.\n",
    "\n",
    "\n",
    "#### Padding은 어떤 기능을 하는가?\n",
    "\n",
    "계속해서 필터를 적용시키면 원본 이미지가 줄어드므로, 사이즈를 유지시켜주는 역할을 한다. 왜 사이즈를 유지시켜야 하는가?\n",
    "\n",
    "유실된 데이터가 중요하지 않은 데이터면 상관없지만, 중요한 데이터 일수도 있으므로 특징이 유실되기 전에 유지시켜주는 의미가 크다.\n",
    "\n",
    "더 나아가, Overfitting도 방지하는데, 그 이유는 원본 데이터에 0값을 넣어서 원래의 특징을 희석시켜버리고 이것을 기반으로 머신러닝 모델이 트레이닝 값에만 정확하게 맞아들어가는 현상도 방지해주는 것이다.\n",
    "\n",
    "\n",
    "#### Pooling을 어떤 기능을 하는가?\n",
    "\n",
    "Convolution 계층을 통해서 어느정도 특징이 추출되었으면, 이 모든 특징들을 쓸 필요가 없다. 필터에서 가장 큰 값이 의미있는 Feature라고 지정했으므로, Max_Pooling을 자주 써서 가장 큰 값(큰 특징)만을 뽑아준다고 생각하면 편안하다. 굳이 고해상도 사진이 있어야만 사물을 판단할 수 있는 것이 아니라, 작은 크기의 사진만으로도 판단할 수 있는 원리이다.\n",
    "\n",
    "풀링은 매번 사용하는 것이 아니라 데이터의 크기를 줄이고 싶을 때 선택적으로 사용하는 것이다.\n",
    "\n",
    "풀링을 잘 쓰면, 전체 데이터의 사이즈를 잘 줄여서 연산에 들어가는 리소스가 줄어들고, 데이터의 크기를 줄이면서 소실이 발생하기 때문에 오버피팅을 방지할 수도 있다.\n",
    "\n",
    "\n",
    "#### DropOut은 어떤 기능을 하는가?\n",
    "\n",
    "Fully Conncected Layer와 Softmax 함수 중간에 DropOut Layer를 넣어주는데, 신경망이 학습중일 때 랜덤하게 뉴런을 꺼서 학습을 방해하여 트레이닝 데이터에 학습이 치우치는 현상을 막아주는 것을 의미한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CNN 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesImage' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-37f9e76b44ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                    [[7],[8],[9]]]], dtype=np.float32)\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'AxesImage' object has no attribute 'show'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADi5JREFUeJzt3X/MnWV9x/H3ZxQqUWarhdGUIpI1ds4tEZ8g6mKaqQk2hi6RJfiHgtE0Osl00WSoCSYmy9Q/XGYwkqpEWAySidG61BgEHC4LjEoKpTSVlmThSRtAsEWiU8q+++O52c4O5+nz9Dr3c84pvl/Jybl/XOe+vlxNPr3uXzRVhSSdrN+bdgGSTk2Gh6QmhoekJoaHpCaGh6QmhoekJmOFR5JXJLktycPd99pF2j2XZE/32TlOn5JmQ8Z5ziPJF4CnqupzSa4B1lbV345o90xVvWyMOiXNmHHD4wCwpaqOJFkP/LiqXjOineEhvciMGx5Hq2rNwPovquoFpy5JjgN7gOPA56rqu4scbzuwHeClL33pGzZv3txc24vdc889N+0SZt6zzz477RJm3r59+35eVWe3/HbVUg2S/Ag4d8SuT59EP+dX1eEkFwJ3JNlbVYeGG1XVDmAHwNzcXO3evfskuvjdcvTo0WmXMPMee+yxaZcw8zZv3vyfrb9dMjyq6u2L7UvyWJL1A6ctjy9yjMPd9yNJfgy8HnhBeEg6dYx7q3YncGW3fCXwveEGSdYmWd0trwPeAjw0Zr+Spmzc8Pgc8I4kDwPv6NZJMpfka12bPwJ2J7kfuJOFax6Gh3SKW/K05USq6kngbSO27wY+2C3/O/An4/Qjafb4hKmkJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmvYRHkkuTHEhyMMk1I/avTnJLt/+eJBf00a+k6Rk7PJKcBnwZeCfwWuA9SV471OwDwC+q6g+BfwA+P26/kqarj5nHxcDBqnqkqn4LfAvYNtRmG3Bjt/xt4G1J0kPfkqakj/DYADw6sD7fbRvZpqqOA8eAV/bQt6Qp6SM8Rs0gqqENSbYn2Z1k9xNPPNFDaZJWSh/hMQ9sHFg/Dzi8WJskq4CXA08NH6iqdlTVXFXNnX322T2UJmml9BEe9wKbkrw6yRnAFcDOoTY7gSu75cuBO6rqBTMPSaeOVeMeoKqOJ7ka+CFwGnBDVe1L8llgd1XtBL4O/FOSgyzMOK4Yt19J0zV2eABU1S5g19C2aweW/wv4yz76kjQbfMJUUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUpNewiPJpUkOJDmY5JoR+69K8kSSPd3ng330K2l6Vo17gCSnAV8G3gHMA/cm2VlVDw01vaWqrh63P0mzoY+Zx8XAwap6pKp+C3wL2NbDcSXNsLFnHsAG4NGB9XngjSPavTvJW4GfAX9TVY8ON0iyHdgOcM4553D77bf3UN6L04EDB6Zdwsw7dOjQtEt4Uetj5pER22po/fvABVX1p8CPgBtHHaiqdlTVXFXNrVmzpofSJK2UPsJjHtg4sH4ecHiwQVU9WVW/6Va/Cryhh34lTVEf4XEvsCnJq5OcAVwB7BxskGT9wOplwP4e+pU0RWNf86iq40muBn4InAbcUFX7knwW2F1VO4G/TnIZcBx4Crhq3H4lTVcfF0ypql3ArqFt1w4sfxL4ZB99SZoNPmEqqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpSS/hkeSGJI8neXCR/UnypSQHkzyQ5KI++pU0PX3NPL4BXHqC/e8ENnWf7cBXeupX0pT0Eh5VdRfw1AmabANuqgV3A2uSrO+jb0nTMalrHhuARwfW57tt/0+S7Ul2J9l99OjRCZUmqcWkwiMjttULNlTtqKq5qppbs2bNBMqS1GpS4TEPbBxYPw84PKG+Ja2ASYXHTuB93V2XS4BjVXVkQn1LWgGr+jhIkpuBLcC6JPPAZ4DTAarqemAXsBU4CPwKeH8f/Uqanl7Co6res8T+Aj7SR1+SZoNPmEpqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGrSS3gkuSHJ40keXGT/liTHkuzpPtf20a+k6enlH7oGvgFcB9x0gjY/qap39dSfpCnrZeZRVXcBT/VxLEmnhr5mHsvxpiT3A4eBT1TVvuEGSbYD2wHOPPNMrrvuugmWd2rZu3fvtEuYeYcOHZp2CS9qkwqP+4BXVdUzSbYC3wU2DTeqqh3ADoC1a9fWhGqT1GAid1uq6umqeqZb3gWcnmTdJPqWtDImEh5Jzk2Sbvnirt8nJ9G3pJXRy2lLkpuBLcC6JPPAZ4DTAarqeuBy4MNJjgO/Bq6oKk9LpFNYL+FRVe9ZYv91LNzKlfQi4ROmkpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmowdHkk2Jrkzyf4k+5J8dESbJPlSkoNJHkhy0bj9SpquPv6h6+PAx6vqviRnAT9NcltVPTTQ5p3Apu7zRuAr3bekU9TYM4+qOlJV93XLvwT2AxuGmm0DbqoFdwNrkqwft29J09PrNY8kFwCvB+4Z2rUBeHRgfZ4XBoykU0gfpy0AJHkZcCvwsap6enj3iJ/UiGNsB7YDnHnmmX2VJmkF9DLzSHI6C8Hxzar6zogm88DGgfXzgMPDjapqR1XNVdXc6tWr+yhN0grp425LgK8D+6vqi4s02wm8r7vrcglwrKqOjNu3pOnp47TlLcB7gb1J9nTbPgWcD1BV1wO7gK3AQeBXwPt76FfSFI0dHlX1b4y+pjHYpoCPjNuXpNnhE6aSmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmowdHkk2Jrkzyf4k+5J8dESbLUmOJdnTfa4dt19J07Wqh2McBz5eVfclOQv4aZLbquqhoXY/qap39dCfpBkw9syjqo5U1X3d8i+B/cCGcY8rabalqvo7WHIBcBfwuqp6emD7FuBWYB44DHyiqvaN+P12YHu3+jrgwd6K68c64OfTLmKA9ZzYrNUDs1fTa6rqrJYf9hYeSV4G/Cvwd1X1naF9vw/8d1U9k2Qr8I9VtWmJ4+2uqrleiuvJrNVkPSc2a/XA7NU0Tj293G1JcjoLM4tvDgcHQFU9XVXPdMu7gNOTrOujb0nT0cfdlgBfB/ZX1RcXaXNu144kF3f9Pjlu35Kmp4+7LW8B3gvsTbKn2/Yp4HyAqroeuBz4cJLjwK+BK2rp86UdPdTWt1mryXpObNbqgdmrqbmeXi+YSvrd4ROmkpoYHpKazEx4JHlFktuSPNx9r12k3XMDj7nvXIE6Lk1yIMnBJNeM2L86yS3d/nu6Z1tW1DJquirJEwPj8sEVrOWGJI8nGfkMThZ8qav1gSQXrVQtJ1HTxF6PWObrGhMdoxV7haSqZuIDfAG4plu+Bvj8Iu2eWcEaTgMOARcCZwD3A68davNXwPXd8hXALSs8Lsup6Srgugn9Ob0VuAh4cJH9W4EfAAEuAe6ZgZq2AP8yofFZD1zULZ8F/GzEn9dEx2iZNZ30GM3MzAPYBtzYLd8I/MUUargYOFhVj1TVb4FvdXUNGqzz28Dbnr8NPcWaJqaq7gKeOkGTbcBNteBuYE2S9VOuaWJqea9rTHSMllnTSZul8PiDqjoCC/+xwDmLtHtJkt1J7k7Sd8BsAB4dWJ/nhYP8v22q6jhwDHhlz3WcbE0A7+6mwN9OsnEF61nKcuudtDcluT/JD5L88SQ67E5pXw/cM7RramN0gprgJMeoj+c8li3Jj4BzR+z69Ekc5vyqOpzkQuCOJHur6lA/FTJqBjF8L3s5bfq0nP6+D9xcVb9J8iEWZkZ/voI1ncikx2c57gNeVf/3esR3gRO+HjGu7nWNW4GP1cB7Xs/vHvGTFR+jJWo66TGa6Myjqt5eVa8b8fke8NjzU7fu+/FFjnG4+34E+DELKdqXeWDwb+3zWHiRb2SbJKuAl7OyU+Yla6qqJ6vqN93qV4E3rGA9S1nOGE5UTfj1iKVe12AKY7QSr5DM0mnLTuDKbvlK4HvDDZKsTbK6W17HwtOtw//fkHHcC2xK8uokZ7BwQXT4js5gnZcDd1R3xWmFLFnT0PnyZSyc007LTuB93R2FS4Bjz5+OTsskX4/o+jnh6xpMeIyWU1PTGE3iCvQyrwi/ErgdeLj7fkW3fQ74Wrf8ZmAvC3cc9gIfWIE6trJwNfoQ8Olu22eBy7rllwD/DBwE/gO4cAJjs1RNfw/s68blTmDzCtZyM3AEeJaFv0E/AHwI+FC3P8CXu1r3AnMTGJ+larp6YHzuBt68grX8GQunIA8Ae7rP1mmO0TJrOukx8vF0SU1m6bRF0inE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTkfwBRARJelRPLdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Image 생성\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImage : (1,3,3,1) \\nFilter : (2,2,1,1) # 2x2 크기의 필터, 1개의 색깔 개수, 1개의 필터 개수\\nStride : (1x1)\\nPadding : VALID\\n\\nConvolution을 한다는 것은, 첫 번째 필터적용 대상인\\n\\n[[[1],[2]],                  [[[1],[1]],\\n [[4],[5]]] 에 대해서    필터 [[1],[1]]] 를 적용하면 1x1 + 2x1 + 4x1 + 5x1 로 같은 위치에 있는 값을 곱해준다 (합성곱, 즉 Convolution)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Image : (1,3,3,1) \n",
    "Filter : (2,2,1,1) # 2x2 크기의 필터, 1개의 색깔 개수, 1개의 필터 개수\n",
    "Stride : (1x1)\n",
    "Padding : VALID\n",
    "\n",
    "Convolution을 한다는 것은, 첫 번째 필터적용 대상인\n",
    "\n",
    "[[[1],[2]],                  [[[1],[1]],\n",
    " [[4],[5]]] 에 대해서    필터 [[1],[1]]] 를 적용하면 1x1 + 2x1 + 4x1 + 5x1 로 같은 위치에 있는 값을 곱해준다 (합성곱, 즉 Convolution)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAACXdJREFUeJzt3V+opPV9x/H3p1r1wnazuk1cTFIj1bQmLcQs1iYQpUYwUtxALJibaFEW20qhVzUIKeSmmpvSYNqwSUO1F0bqRbMphhJrlgTKWpei2cRgXKXBZZeYmLJlaZt0028v5kk6nMzZc77Oc2bmrO8XDPPMPL/z/L6MfHz+7A++qSokbd7PLbsAabsxNFKToZGaDI3UZGikJkMjNc0VmiQXJflykheG953rjPtxkmeG14F55pSWLfP8O02STwA/qKr7k9wL7KyqP5kx7lRVXThHndLKmDc0zwPXV9WJJLuBg1X19hnjDI3OGvPe07ypqk4ADO9vXGfcBUkOJzmU5INzzikt1bkbDUjyBHDJjF33NeZ5a1UdT3I58GSSI1X14oy59gH7ho/vbhz/de/CCz2Rd506der7VfVL3b/bMDRV9f719iX5bpLdU5dnr6xzjOPD+0tJDgLvAn4mNFW1H9g/HNtFcQ179uxZdgnbzsGDB7/zWv5u3suzA8Dtw/btwBfWDkiyM8n5w/Yu4L3Ac3POKy3NvKG5H7gxyQvAjcNnkuxJ8tlhzK8Bh5M8C3wFuL+qDI22rQ0vz86kql4Fbpjx/WHgrmH7n4Ffn2ceaZW4IkBqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopKZRQpPkpiTPJzk6NKxdu//8JI8O+59KctkY80rLMHdokpwDfAr4AHAV8OEkV60Zdifw71X1K8CfAw/MO6+0LGOcaa4BjlbVS1X1I+DzwN41Y/YCDw3bjwE3JMkIc0sLN0ZoLgVenvp8bPhu5piqOg2cBC4eYW5p4ebqhDaYdcZY22R2M2PWdneWVtIYZ5pjwFumPr8ZOL7emCTnAjuAH6w9UFXtr6o9VWWrYq2sMULzNHBFkrclOQ+4jUnX52nTXaBvBZ6sKluea1ua+/Ksqk4nuQf4R+Ac4HNV9c0kHwcOV9UB4K+Bv01ylMkZ5rZ555WWZYx7GqrqceDxNd99bGr7v4HfHWMuadlcESA1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UtOiujvfkeR7SZ4ZXneNMa+0DHO32pjq7nwjk45nTyc5UFXPrRn6aFXdM+980rItqruzdNYYo6nTrO7Ovzlj3IeSvA/4NvDHVfXyjDE/deWVV7J///4Rynt9uO6665ZdwraTzOqfvLExzjSb6dz8ReCyqvoN4AngoZkHSvYlOZzk8MmTJ0coTRrfQro7V9WrVfXD4eNngHfPOtB0d+cdO3aMUJo0voV0d06ye+rjLcC3RphXWopFdXf+oyS3AKeZdHe+Y955pWVZVHfnjwIfHWMuadlcESA1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UtNY3Z0/l+SVJN9YZ3+SfHLo/vz1JFePMa+0DGOdaf4GuOkM+z8AXDG89gF/NdK80sKNEpqq+iqTZk3r2Qs8XBOHgDes6Y4mbRuLuqeZ1QH60gXNLY1qUaHZTAdouztrW1hUaDbsAA12d9b2sKjQHAA+MjxFuxY4WVUnFjS3NKpRGtUmeQS4HtiV5Bjwp8DPA1TVp5k0sb0ZOAr8J/B7Y8wrLcNY3Z0/vMH+Av5wjLmkZXNFgNRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYZGajI0UpOhkZoMjdRkaKQmQyM1GRqpydBITYvq7nx9kpNJnhleHxtjXmkZRmm1waS784PAw2cY87Wq+p2R5pOWZlHdnaWzxiLvaX4rybNJvpTkHQucVxpVJk3KRjhQchnwD1X1zhn7fhH436o6leRm4C+q6ooZ4/YB+4aP7wRm3iMt2S7g+8suYh2rWtuq1vX2qvqF7h8tJDQzxv4bsKeq1v0hkxyuqj2jFDeiVa0LVre2s62uhVyeJbkkSYbta4Z5X13E3NLYFtXd+Vbg95OcBv4LuK3GOsVJC7ao7s4PMnkk3bH/tVe0pVa1Lljd2s6quka7p5FeL1xGIzWtTGiSXJTky0leGN53rjPux1PLcQ5sYT03JXk+ydEk987Yf36SR4f9Tw1PD7fcJuq6I8n3pn6juxZU10ZLqZLkk0PdX09y9YrU1V/iVVUr8QI+Adw7bN8LPLDOuFMLqOUc4EXgcuA84FngqjVj/gD49LB9G/DoitR1B/DgEv77vQ+4GvjGOvtvBr4EBLgWeGpF6rqeyT+VbPqYK3OmAfYCDw3bDwEfXGIt1wBHq+qlqvoR8Hkm9U2brvcx4IafPFZfcl1LURsvpdoLPFwTh4A3JNm9AnW1rVJo3lRVJwCG9zeuM+6CJIeTHEqyVcG6FHh56vOx4buZY6rqNHASuHiL6unUBfCh4RLosSRv2eKaNmuztS9Da4nXWKucNyXJE8AlM3bd1zjMW6vqeJLLgSeTHKmqF8ep8KdmnTHWPmbczJixbWbOLwKPVNUPk9zN5Gz421tc12Ys4/fajH8Ffrn+f4nX3wM/s8Rr2kJDU1XvX29fku8m2V1VJ4bT9ivrHOP48P5SkoPAu5hc54/pGDD9f+g3A8fXGXMsybnADrZ+pfeGdVXV9EqLzwAPbHFNm7WZ33Thquo/prYfT/KXSXbVGZZ4rdLl2QHg9mH7duALawck2Znk/GF7F/Be4LktqOVp4Iokb0tyHpMb/bVP6qbrvRV4soY7yy20YV1r7hNuAb61xTVt1gHgI8NTtGuBkz+5HF+m17TEa9FPWc7wlONi4J+AF4b3i4bv9wCfHbbfAxxh8tToCHDnFtZzM/BtJmex+4bvPg7cMmxfAPwdcBT4F+DyBf1OG9X1Z8A3h9/oK8CvLqiuR4ATwP8wOavcCdwN3D3sD/Cpoe4jTBbsrkJd90z9XoeA92x0TFcESE2rdHkmbQuGRmoyNFKToZGaDI3UZGikJkMjNRkaqen/AJ8IgtACvr2/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convolution 계산 (일반)\n",
    "\n",
    "#Image 크기\n",
    "print(\"image.shape\", image.shape) #(1,3,3,1)\n",
    "\n",
    "#Filter 크기는 conv2d에서 연산하는 사이즈와 맞아야 함\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                       [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "\n",
    "#conv2d : Convolution 연산\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='VALID') #padding='SAME' 으로 넣어주면 알아서 같은 사이즈가 되도록 padding을 채워줌\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "\n",
    "#시각화 하기 위한 처리과정\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Padding을 알아서 넣은 형태의 Convolution (padding='SAME')\n",
    "\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 필터 3개짜리로 구현\n",
    "\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "#필터 자체의 갯수를 늘려줌\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Pooling\n",
    "\n",
    "\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME') #kernel size는 2,2의 중간값으로 이용, strides는 1,1씩 이동\n",
    "print(pool.shape) #max_pooling을 하는 크기\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. MNIST 데이터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-50-fd947b007c97>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ALEXa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ALEXa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ALEXa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ALEXa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ALEXa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aee70ab400>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADZxJREFUeJzt3X+o1fUdx/HXe6YUFf1g6SSdN+2Xqz9c3WJRDNcyagQ2aNaFlquxu8Igw2AiQf7RIIZmg6C40WUG022xftxibGoEJq6lhnjbbCvCplOumqVXikJ974/7NW52v59zPOf7Pd9z7/v5ALnnfN/fH28Ovu73e+73x8fcXQDi+UbVDQCoBuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUKa3cmJlxOSFQMne3euZras9vZjeZ2b/N7H0zW9zMugC0ljV6bb+ZjZP0H0lzJO2StElSl7v/K7EMe36gZK3Y818t6X13/8Ddv5D0B0lzm1gfgBZqJvznS9o57P2ubNpXmFm3mW02s81NbAtAwZr5g99IhxZfO6x39x5JPRKH/UA7aWbPv0vS1GHvp0ja3Vw7AFqlmfBvknSRmV1gZhMk3SGpr5i2AJSt4cN+dz9iZvdL+pukcZJ63f2fhXUGoFQNn+praGN85wdK15KLfACMXoQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1fAQ3ZJkZjskDUo6KumIu3cW0RSA8jUV/swP3H1/AesB0EIc9gNBNRt+l7TGzLaYWXcRDQFojWYP+691991mNlHSWjN7193XD58h+6XALwagzZi7F7Mis6WSDrv7ssQ8xWwMQC53t3rma/iw38xON7Mzj7+WdKOkdxpdH4DWauawf5KkF83s+HpWuftfC+kKQOkKO+yva2Mc9gOlK/2wH8DoRviBoAg/EBThB4Ii/EBQhB8Iqoi7+lCxu+++O7dW61TuRx99lKzPnDkzWd+4cWOyvmHDhmQd1WHPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBjZnz/F1dXcn6FVdckaynzpW3u7PPPrvhZY8ePZqsT5gwIVn/7LPPkvVPP/00t9bf359cdt68ecn6vn37knWksecHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBG1aO7ly9fnlt74IEHksuOGzeumU2jAq+//nqyXuvajoGBgSLbGTV4dDeAJMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrmeX4z65V0i6S97n55Nu1cSX+U1CFph6R57v5xzY01eZ5/586dubUpU6Ykl922bVuyXuu+9DLVerb9Sy+91KJOTt6cOXOS9bvuuiu31tHR0dS2a10HcPvtt+fWxvKzAIo8z/87STedMG2xpNfc/SJJr2XvAYwiNcPv7uslHThh8lxJK7PXKyXdWnBfAErW6Hf+Se6+R5KynxOLawlAK5T+DD8z65bUXfZ2AJycRvf8A2Y2WZKyn3vzZnT3HnfvdPfOBrcFoASNhr9P0vzs9XxJLxfTDoBWqRl+M1st6e+SLjGzXWb2c0mPSZpjZu9JmpO9BzCKjKr7+S+++OLc2mWXXZZcdt26dcn64OBgQz0hbfr06bm1V199NbnszJkzm9r2Qw89lFtLPRtitON+fgBJhB8IivADQRF+ICjCDwRF+IGgRtWpPowtt912W7L+/PPPN7X+/fv359bOO++8ptbdzjjVByCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IqfbguxHbffffl1q666qpSt33qqafm1q688srkslu2bCm6nbbDnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqr53H4z65V0i6S97n55Nm2ppF9I2pfNtsTd/1JzYzy3vxSTJ0/Ord15553JZRcuXFh0O1+R6s2srsfLl+LQoUPJ+llnndWiTopX5HP7fyfpphGmr3D3Wdm/msEH0F5qht/d10s60IJeALRQM9/57zezbWbWa2bnFNYRgJZoNPxPSZohaZakPZKW581oZt1mttnMNje4LQAlaCj87j7g7kfd/ZikZyRdnZi3x9073b2z0SYBFK+h8JvZ8D/h/ljSO8W0A6BVat7Sa2arJc2W9E0z2yXpEUmzzWyWJJe0Q9IvS+wRQAlqht/du0aY/GwJvYR1ww03JOu17j3v7u7OrU2fPr2hnsa63t7eqluoHFf4AUERfiAowg8ERfiBoAg/EBThB4Li0d0FuPDCC5P1p59+Olm//vrrk/Uyb3398MMPk/WPP/64qfU//PDDubXPP/88ueyTTz6ZrF9yySUN9SRJu3fvbnjZsYI9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExXn+Oj344IO5tQULFiSXnTFjRrJ++PDhZP2TTz5J1p944oncWq3z2Rs3bkzWa10HUKaDBw82tfzg4GBu7ZVXXmlq3WMBe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrz/HW65pprcmu1zuP39fUl68uX5452Jklav359sj5azZo1K1mfNm1aU+tPPS/g3XffbWrdYwF7fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquZ5fjObKuk5Sd+SdExSj7v/1szOlfRHSR2Sdkia5+7NPeS9jd177725tW3btiWXffTRR4tuZ0yoNd7BpEmTmlr/unXrmlp+rKtnz39E0iJ3nynpe5IWmNl3JC2W9Jq7XyTptew9gFGiZvjdfY+7v529HpS0XdL5kuZKWpnNtlLSrWU1CaB4J/Wd38w6JH1X0j8kTXL3PdLQLwhJE4tuDkB56r6238zOkPRnSQvd/VC948eZWbek7sbaA1CWuvb8ZjZeQ8H/vbu/kE0eMLPJWX2ypL0jLevuPe7e6e6dRTQMoBg1w29Du/hnJW1398eHlfokzc9ez5f0cvHtASiLuXt6BrPrJL0hqV9Dp/okaYmGvvf/SdK3Jf1X0k/c/UCNdaU3hlCWLVuWrC9atChZr/VI85tvvjm39uabbyaXHc3cva7v5DW/87v7Bkl5K/vhyTQFoH1whR8QFOEHgiL8QFCEHwiK8ANBEX4gKB7djVL19/fn1i699NKm1r1mzZpkfSyfyy8Ce34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrz/ChVR0dHbu2UU9L//Q4ePJisr1ixopGWkGHPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcZ4fTenq6krWTzvttNza4OBgctnu7vQob9yv3xz2/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egazqZKek/QtScck9bj7b81sqaRfSNqXzbrE3f9SY13pjaHtjB8/Pll/6623kvXUs/lXr16dXPaee+5J1jEyd7d65qvnIp8jkha5+9tmdqakLWa2NqutcPdljTYJoDo1w+/ueyTtyV4Pmtl2SeeX3RiAcp3Ud34z65D0XUn/yCbdb2bbzKzXzM7JWabbzDab2eamOgVQqLrDb2ZnSPqzpIXufkjSU5JmSJqloSOD5SMt5+497t7p7p0F9AugIHWF38zGayj4v3f3FyTJ3Qfc/ai7H5P0jKSry2sTQNFqht/MTNKzkra7++PDpk8eNtuPJb1TfHsAylLPX/uvlfRTSf1mtjWbtkRSl5nNkuSSdkj6ZSkdolK1TgWvWrUqWd+6dWtube3atbk1lK+ev/ZvkDTSecPkOX0A7Y0r/ICgCD8QFOEHgiL8QFCEHwiK8ANB1bylt9CNcUsvULp6b+llzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQbV6iO79kj4c9v6b2bR21K69tWtfEr01qsjeptU7Y0sv8vnaxs02t+uz/dq1t3btS6K3RlXVG4f9QFCEHwiq6vD3VLz9lHbtrV37kuitUZX0Vul3fgDVqXrPD6AilYTfzG4ys3+b2ftmtriKHvKY2Q4z6zezrVUPMZYNg7bXzN4ZNu1cM1trZu9lP0ccJq2i3paa2f+yz26rmf2oot6mmtnrZrbdzP5pZg9k0yv97BJ9VfK5tfyw38zGSfqPpDmSdknaJKnL3f/V0kZymNkOSZ3uXvk5YTP7vqTDkp5z98uzab+RdMDdH8t+cZ7j7r9qk96WSjpc9cjN2YAyk4ePLC3pVkk/U4WfXaKveargc6tiz3+1pPfd/QN3/0LSHyTNraCPtufu6yUdOGHyXEkrs9crNfSfp+VyemsL7r7H3d/OXg9KOj6ydKWfXaKvSlQR/vMl7Rz2fpfaa8hvl7TGzLaYWXfVzYxgUjZs+vHh0ydW3M+Jao7c3EonjCzdNp9dIyNeF62K8I/0iKF2OuVwrbtfIelmSQuyw1vUp66Rm1tlhJGl20KjI14XrYrw75I0ddj7KZJ2V9DHiNx9d/Zzr6QX1X6jDw8cHyQ1+7m34n6+1E4jN480srTa4LNrpxGvqwj/JkkXmdkFZjZB0h2S+iro42vM7PTsDzEys9Ml3aj2G324T9L87PV8SS9X2MtXtMvIzXkjS6viz67dRryu5CKf7FTGE5LGSep191+3vIkRmNl0De3tpaE7HldV2ZuZrZY0W0N3fQ1IekTSS5L+JOnbkv4r6Sfu3vI/vOX0NltDh65fjtx8/Dt2i3u7TtIbkvolHcsmL9HQ9+vKPrtEX12q4HPjCj8gKK7wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8Bp+YC7BbcNBcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Image 불러오기\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "img = mnist.train.images[0].reshape(28,28) #28x28으로 reshape\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_9:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convolution Layer 통과시키기\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1) # -1은 알아서 계산하라는 reshape의 방법, 28x28으로 사이즈 규정, 색깔은 1가지 \n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01)) #3x3짜리 필터, 색깔은 1가지, 필터 개수는 5개\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME') #stride는 2x2로 움직이고, padding을 줘서 동일한 결과를 내겠다는 뜻\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_4:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Max Pooling\n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME') #Convolution결과인 conv2d, Pooling하는 커널사이즈는 2x2(중간값), stride는 2x2 \n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CNN으로 MNIST 문제 해결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#첫 번째 Convolution Layer\n",
    "\n",
    "# 초기 들어가는 데이터는 28 x 28\n",
    "X = tf.placeholder(tf.float32, [None, 784]) #784 = 28 x 28 개의 픽셀을 갖는 X (인풋값)\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # -1로 알아서 맞춰보고, 28x28 사이즈, 색깔은 1가지 로 reshape \n",
    "Y = tf.placeholder(tf.float32, [None, 10]) # 마지막에 Fully Connected Layer를 이용해서 10개로 분류할거야\n",
    "\n",
    "# 들어가는 이미지의 형태 (?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) #필터 사이즈는 3x3, 색은 1가지, 필터 개수는 32개\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME') #STRIDE는 1로 해서 32개의 필터를 모두 Convolution을 통과시킴\n",
    "L1 = tf.nn.relu(L1) # ReLU 통과\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME') #Max_Pooling, 커널 사이즈는 2x2, stride는 2x2로 이동\n",
    "\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#두 번째 Convolution Layer\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) #필터 사이즈는 3x3, 이전 필터의 개수와 같은 32개, 이번에는 64개 필터 생성\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#세 번째 Convolution Layer\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Fully Connected Layer에 넣기 전에, 입체적으로 들어가있는 값을 일직선(1차원)으로 쭉 펼쳐주어야 함\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FC를 처음으로 만들어줌\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#마지막으로 펼쳐서 만드는 Fully Connected Layer\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 실시\n",
    "\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
